# Qwen模型微调
该项目核心围绕**基于RAG技术的大模型微调（尤其是LoRA轻量化微调）与推理部署**展开，具体功能拆解如下：

### 1. 核心方向：RAG+大模型微调&推理
RAG是结合“检索外部知识库”和“大模型生成”的技术，解决大模型幻觉、知识时效性差的问题；而项目中`train`/`train_lora`、`inference`/`inference_lora`的命名，说明聚焦于**大模型的LoRA（低秩适配）轻量化微调** 和微调后的**推理/生成** 能力，且整体结合了RAG技术体系。

### 2. 各文件核心作用（基于命名&行业通用逻辑）
| 文件 | 核心功能 |
|------|----------|
| `data.py` | 数据处理模块：负责RAG场景下数据集的加载、清洗、格式化（如构建检索库、处理微调样本）、划分训练/测试集等，为训练和推理提供数据支撑。 |
| `train.py` | 基础训练模块：实现大模型的全量/基础微调流程（无LoRA），适配RAG场景的训练目标（如优化检索结果的生成对齐、增强知识库关联能力）。 |
| `train_lora.py` | LoRA轻量化训练模块：基于LoRA技术对大模型做轻量化微调（仅训练少量参数），降低硬件成本，同时针对RAG场景优化模型生成逻辑。 |
| `inference.py` | 基础推理模块：加载微调后的基础模型，实现RAG流程的推理（如接收用户查询→检索知识库→结合知识库内容生成回答）。 |
| `inference_lora.py` | LoRA推理模块：加载LoRA微调后的模型（或基础模型+LoRA权重），执行RAG推理，是轻量化微调后的核心推理入口。 |

### 3. 项目整体流程（推测）
1. 通过`data.py`处理RAG专用数据集（如“问题-知识库片段-标准答案”格式的样本）；
2. 选择`train.py`（全量微调）或`train_lora.py`（轻量化微调）对大模型进行针对RAG场景的定制训练；
3. 训练完成后，通过`inference.py`或`inference_lora.py`加载模型，实现“检索外部知识+模型生成回答”的端到端RAG推理。
